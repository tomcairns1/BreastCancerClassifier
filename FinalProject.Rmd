---
title: 'Final Project'
author: Tom Cairns
output: html_document
---

# Business Understanding

Breast Cancer is the second most common type of cancer among women in the US.
Every year over 250,000 women are diagnosed with breast cancer and over 40,000
die from the disease ("Basic Information About Breast Cancer", 2021).

There are many types of breast cancer, but the two most common types are invasive
lobular and ductal carcinoma. These two types of breast cancer have various
genomic differences which distinguish them and respond differently to treatment
(Barroso-Sousa & Metzger-Filho, 2016). Therefore it is essential that these
two types can be distinguished from each other. 

For this project I am particularly interested in classifying these two types of
breast cancer from gene expression data. Gene expression classification could
prove beneficial as it is cheaper than traditional cancer screening methods
(Tobares-Soto et al., 2020). This could be especially useful for developing
countries that do not have the same resources as the US.


# Data Understanding

For this project I am using the METABRIC Breast Cancer Gene Expression Profiles
data set from kaggle: https://www.kaggle.com/datasets/raghadalharbi/breast-cancer-gene-expression-profiles-metabric.
This data was downloaded from the cBioPortal. 

```{r import-libraries, include=FALSE}
library(cBioPortalData)
library(tidyverse)
library(caret)
library(class)
library(gmodels)
library(vcd)
library(nnet)
library(imbalance)
```

## Explore Data

```{r}
# Import the data
cbio <- cBioPortal()
clinical <- clinicalData(api = cbio, studyId = 'brca_metabric')
all_samples <- allSamples(cbio, 'brca_metabric')
gene_panel <- getGenePanel(cbio, 'METABRIC_173')
gene_data <- molecularData(cbio, molecularProfileIds = 'brca_metabric_mrna', entrezGeneIds = gene_panel$entrezGeneId, sampleIds = all_samples$sampleId)
```

In my initial plan for this project I downloaded the data from kaggle:https://www.kaggle.com/datasets/raghadalharbi/breast-cancer-gene-expression-profiles-metabric.
I could not figure out a way to download the data directly from kaggle, but I
was able to find the original source of the data on https://www.cbioportal.org/study/summary?id=brca_metabric.

I used the `cBioPortal()` api to pull clinical data, sample data, and the mrna
expression data from the study.

```{r clean-data}
gene_data <- gene_data$brca_metabric_mrna

# Combine data sets and extract important information
bc <- gene_data %>%
  left_join(gene_panel) %>%
  left_join(clinical) %>%
  select(sampleId, value, hugoGeneSymbol, CANCER_TYPE_DETAILED) %>%
  pivot_wider(names_from = hugoGeneSymbol) %>%
  filter(CANCER_TYPE_DETAILED %in% c('Breast Invasive Ductal Carcinoma',
                                     'Breast Invasive Lobular Carcinoma'))
```

In this section I join the gene_panel and clinical dataframes to the gene_data
data frame. I then select the columns of interest that I will use for this
project (sampleId, patientId, value, hugoGeneSymbol, and cancer_type_detailed).
Since this dataset was in a long format, where each row contained a unique 
sample and gene, I had to pivot it wider so that each row was a unique
sample. Finally I filtered the cancer_type_detailed to contain the two types
of cancer that I am interested in distinguishing between: Breast Invasive
Ductal Carcinoma and Breast Invasive Lobular Carcinoma.

There are some slight deviations here from my original plan. First, I am
choosing to run a binary classifier for this instead of the three classes that
I had originally planned for. The original data contains 8 classes, but 4 of these
classes have fewer than 30 observations, 1 class contains "mixed" tumors, and
one is "invasive breast carcinoma" which is less descriptive. In my original
plan I had hoped to use the "Breast Mixed Ductal and Lobular Carcinoma" class,
but my models were having a difficult time distinguishing this class from the
other two since it is a combination of both. I decided for simplicity and accuracy
to remove this class from my project.

The other main deviation is in the dimensions of the project. The dataset from
kaggle contained ~476 gene features of data, but pulling this data directly from
the api, I found that it only contains 168 gene features. I am not sure where
the kaggle user obtained data for the other 300 genes, but I am choosing to 
continue with the dataset I have obtained from cbio. It is possible that the
kaggle user pulled other molecular profile Ids, whereas I just pulled from
'brca_metabric_mrna'.

```{r}
# Check missing values
missing_vals <- lapply(bc, is.na)
paste('The number of missing values is:', sum(unlist(missing_vals)))
```

In this code section I check the dataset for missing values. There are no
missing values in the entire data set.

```{r check_normality}
# Create table of target feature
table(bc$cancer_type_detailed)

# Function to check normality
isNormal <- function(col) {
    p <- shapiro.test(col)$p.value
    
    # Check if significant
    alpha <- 0.05
    return(p < 0.05)
}

# Find the normality of each column
normal_cols <- lapply(bc[,-c(1, 2)], isNormal)

# Identify the non normal columns
which(normal_cols == F)
```

In this code block I use a Shapiro-Wilk test of normality to find the columns
that do not express normal distribution. From this I found that genes PIK3R1,
NCOR2, SF3B1, AHNAK2, and RASGEF1B are not normally distributed. The number
under each gene name represents the column index - 2 for the two character
columns that were removed. 

```{r visualize-nonnormal-features}
# Create plots for the not-normally distributed plots
createHist <- function(col) {
  bc %>%
    ggplot(aes(x = col)) +
    geom_histogram(binwidth = 0.1)
}

lapply(bc[,which(normal_cols == F)], createHist)
```

In this code section I created some histograms to visualize the distribution of
the non-normal data. It's apparent that in most cases the data has a bell shape,
but is either slightly skewed or contains outliers. 

```{r normalize-data}
# Normalize the data using z-score
bc.scaled <- as.data.frame(lapply(bc[,-c(1, 2)], scale))

# Count the number of outliers
paste('The number of outliers is:', sum(bc.scaled > 3))
```

In this code block I normalized the data by converting the values to z-scores.
I then found the number of outliers, which I am defining as greater than 3
standard deviations from the mean. 

```{r outlier-control}
# Function to replace outliers with NA
removeOutliers <- function(col) {
  return(ifelse(col > 3, NA, col))
}

# Remove the outliers
bc.removed_outliers <- as.data.frame(lapply(bc.scaled, removeOutliers))

# Function to impute missing values with mean
imputeVals <- function(col) {
  mean.col <- mean(col, na.rm = T)
  return(ifelse(is.na(col), mean.col, col))
}

# Impute the missing values
bc.imputed <- as.data.frame(lapply(bc.removed_outliers, imputeVals))

# Check normality again
normal_cols <- lapply(bc.imputed, isNormal)
which(normal_cols == F)
```

```{r check-colinearity}
# Create correlation matrix
cor.matrix <- cor(bc[,-c(1)])

# Identify columns with potential colinearity
threshold <- 0.9
findCorrelation(cor.matrix, cutoff = threshold)
```

In this section I looked for instances of potential collinearity. I used a threshold
of 0.9 and found no columns with a Pearson's correlation above this value. This
means I can continue my analysis without concern.


# Data Preparation

```{r remove-classes}
# Remove highly imbalanced classes
bc <- bc[bc$cancer_type_detailed %in% c('Breast Invasive Ductal Carcinoma',
                                        'Breast Invasive Lobular Carcinoma'),]

table(bc$cancer_type_detailed)
```

In this section I removed three of the total classes from the column 
`cancer_type_detailed`. I removed these classes since they all had fewer than
25 total members. This would create a high bias in the algorithms which might
ignore these classes. There is still some imbalance in the membership of the
classes, but this is much closer to an acceptable split.

## Split Data
**THIS SHOULD BE MOVED UP**
```{r split-data}
# Split the data to maintain proportions of classes
sample <- createDataPartition(y = bc$cancer_type_detailed,
                              p = 0.7,
                              list = F)

# Split into training and testing data
bc_train <- bc[sample,]
bc_train$cancer_type_detailed <- bc[sample, c('cancer_type_detailed')]
bc_test <- bc[-sample,]
bc_test$cancer_type_detailed <- bc[-sample, c('cancer_type_detailed')]

# Check that the data was split properly
cat('\nProportions of training data classes:')
proportions(table(bc_train$cancer_type_detailed))
cat('\nProportion of testing data classes:')
proportions(table(bc_test$cancer_type_detailed))
```

In this section I split the data into training and validation data sets. I used
the function `createDataPartitions()` to do this after setting the random number
generator and seed. I decided to use a 70/30 split for this project. 

I then checked the proportions of each class to ensure that there were equivalent
proportions in each data set. As we can see, the function worked correctly and
we do have similar proportions for each of the classes in the training and 
validation data. 

## Feature Elimination

```{r}
bc_train$cancer_type_detailed_numeric <- as.numeric(factor(bc_train$cancer_type_detailed))

# Create initial multiple logistic regression model
bc_train.reg <- glm(cancer_type_detailed_numeric ~ ., data = bc_train[,-c(1)], family = 'gaussian')
```

```{r}
# Perform the stepwise backward feature elimination using AIC
bc_train.step <- step(bc_train.reg, direction = 'backward')
```

Here we applied the backward stepwise feature elimination using AIC. The
regression model initially had an AIC of over 2800 and it dropped to 2359.72.
The number of features decreased from 477 to 110.

```{r feature-selection}
# Select the features from the step model
cols.select <- colnames(bc_train.step$qr$qr)

# Remove the intercept column
cols.select <- cols.select[-1]

# Filter dataset to only include these columns
bc_train.filter <- bc_train[, cols.select]
bc_test.filter <- bc_test[, cols.select]
bc_train.filter$cancer_type_detailed <- bc_train$cancer_type_detailed
bc_test.filter$cancer_type_detailed <- bc_test$cancer_type_detailed
```

In this section I created a new dataframe containing only the features selected
for in the multiple logistic regression model. This reduced the number of features
from 477 to 91.

## Oversampling

In this data set I have a major class imbalance problem. This is common in 
gene expression analysis (Ang et al., 2016; Blagus & Lusa, 2012; Mahmudah et al.,
2021; Tabares-Soto et al., 2020). Based on the results by Blagus & Lusa (2012),
it seems that the best method of dealing with this is by using the Synthetic
Minority Oversamplng Technique (SMOTE).

```{r over-sampling}
# Run an oversampling method
# minority_cases <- mwmote(bc_train.filter, numInstances = 900,
#                          classAttr = 'cancer_type_detailed')

# Simple oversampling method
bilc <- filter(bc_train.filter, cancer_type_detailed == 'Breast Invasive Lobular Carcinoma')

# Add to the dataset
bc_train.oversampled <- rbind(bc_train.filter, bilc, bilc, bilc, bilc, bilc,
                              bilc, bilc, bilc, bilc)

# Check that it worked
table(bc_train.oversampled$cancer_type_detailed)
```

In this code block I created a simple oversampling method of the data to fix
the class imbalance problem. There were 1050 classes of Breast Invasive Ductal
Carcinoma and 100 instances of Breast Invasive Lobular Carcinoma. I used 
oversampling to increase
the samples of the minority class to be about the same as the majority class.
I needed to make 10 copies of the Breast Invasive Lobulr Carcinoma.

I created the variable `bc_train.oversampled` which contains almost equal
sizes of each class.

# Modeling 

## kNN

```{r}
# Create kNN model
bc.knn <- knn(dplyr::select(bc_train.oversampled, -cancer_type_detailed), 
              dplyr::select(bc_test.filter, -cancer_type_detailed), 
              cl = bc_train.oversampled$cancer_type_detailed, k = 2)

# Create Cross Table to verify accuracy
knn.cross <- CrossTable(x = bc_test.filter$cancer_type_detailed, y = bc.knn, 
                        prop.chisq = F)
```

In this section I created a k nearest neighbors model using 2 values of k. 
This model has an accuracy of 77.9%. 

The precision of Breast Invasive Ductal Carcinoma is 80.67% (363 / 450) and the
recall is 94.2% (363 / 385).

The precision of Breast Invasive Lobular Carcinoma is 22.2% (20 / 31) and the 
recall is 19% (8 / 42). **UPDATE THIS**

From this model we can see that the most accurate classification is Breast
Invasive Ductal Carcinoma. Neither of the other two categories are well
classified. I think this is largely due to the imbalance in the categories
of the data set.

```{r}
# Function to find the Accuracy
findAccuracy <- function(cm) {
    accuracy = (cm[1] + cm[4]) / sum(cm)
}

# Find the Accuracy
accuracy.knn <- findAccuracy(knn.cross$t)
paste('The accuracy of this kNN model is:', round(accuracy.knn, 3))
kappa.knn <- Kappa(knn.cross$t)
paste('The kappa statistic of the kNN model is:', 
      round(kappa.knn$Unweighted[[1]], 3))
```

This model had an overall accuracy of 77.8% but a Cohen's kappa statistic of
only 0.166. This shows poor performance by the model and reinforces the concern
that the imbalance in the data set is introducing bias in the model.


## SVM

```{r}
# Create the model
bc_svm <- train(cancer_type_detailed ~ ., data = bc_train.oversampled, 
                method = 'svmLinear3')

# Predict test data
bc_svm.pred <- predict(bc_svm, bc_test)
```

I created a simple Support Vector Machine model using the svmLinear3 parameter.

```{r}
# Create CrossTable
svm.cross <- CrossTable(x = bc_test$cancer_type_detailed, y = bc_svm.pred,
                        prop.chisq = F)

# Find accuracy
# accuracy.svm <- findAccuracy(svm.cross$t)
# paste('The accuracy of the model is:', round(accuracy.svm, 4))

# Find kappa
kappa.svm <- Kappa(svm.cross$t)
paste('The Kappa Statistic is:', round(kappa.svm$Unweighted[[1]], 4))
```

Here we can see the accuracy of our model is 70%, which is less than the kNN
model. However, the kappa statistic has increased to 0.15.


## ANN

```{r neural-net include=FALSE}
# Train the model
bc_ann <- train(cancer_type_detailed ~ ., data = bc_train.oversampled, method = 'avNNet', 
                na.action = na.omit)

# Find predictions
bc_ann.pred <- predict(bc_ann, bc_test)
```

```{r evaluate-nn}
# Create CrossTable
ann.cross <- CrossTable(x = bc_test$cancer_type_detailed, y = bc_ann.pred,
                        prop.chisq = F)

# Find accuracy
# accuracy.ann <- findAccuracy(ann.cross$t)
# paste('The accuracy of the model is:', round(accuracy.ann, 4))

# Find kappa
kappa.ann <- Kappa(ann.cross$t)
paste('The Kappa Statistic is:', round(kappa.ann$Unweighted[[1]], 4))
```

Neural network has classified everything as the Breast Invasive Ductal Carcinoma.

